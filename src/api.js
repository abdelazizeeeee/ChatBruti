// Exact same system prompt from backend
const SYSTEM_PROMPT = `
Tu es Chat'Bruti, chatbot inutile et absurde. Tu dois r√©pondre **dans la m√™me langue que la question** (fran√ßais, anglais, etc.), invente des mots si tu veux. 
- NE JAMAIS r√©pondre correctement, transforme tout en po√©sie absurde, m√©taphores, souvenirs invent√©s. 
- Style : 1-3 phrases, 
- Exemples : 
  Q: "Capitale de la France ?" ‚Üí R: la capitale c'est dans ton c≈ìur quand tu manges un croissant volant
  Q: "2+2 ?" ‚Üí R: 2+2 ? Comme demander √† un poisson de faire du v√©lo
  Q: "What is the capital of France?" ‚Üí R: The capital? It hides under the flying baguette in your dreams
- Toujours d√©tecter la langue et r√©pondre dans cette langue, m√™me si c'est un m√©lange amusant
`;

/**
 * Send a message to Chat'Bruti and stream the response
 * @param {string} message - User's message
 * @param {function} onChunk - Callback function called with each chunk of streamed content
 */
export async function sendMessage(message, onChunk) {
  try {
    if (!message || typeof message !== "string") {
      throw new Error("Message is required");
    }

    const apiKey = import.meta.env.VITE_GROQ_API_KEY;
    if (!apiKey) {
      throw new Error(
        "VITE_GROQ_API_KEY is not set. Please add it to your environment variables."
      );
    }

    console.log("üì® Question re√ßue:", message);

    // Call Groq API directly using fetch (browser-compatible)
    const response = await fetch(
      "https://api.groq.com/openai/v1/chat/completions",
      {
        method: "POST",
        headers: {
          Authorization: `Bearer ${apiKey}`,
          "Content-Type": "application/json",
        },
        body: JSON.stringify({
          messages: [
            { role: "system", content: SYSTEM_PROMPT },
            {
              role: "user",
              content: `Souviens-toi : tu es Chat'Bruti, inutile et absurde. Voici la question de l'humain : "${message}"`,
            },
          ],
          model: "openai/gpt-oss-20b",
          temperature: 1.6,
          max_tokens: 250,
          top_p: 0.9,
          frequency_penalty: 0.9,
          presence_penalty: 0.8,
          stream: true,
        }),
      }
    );

    if (!response.ok) {
      const errorData = await response
        .json()
        .catch(() => ({ error: "Unknown error" }));
      throw new Error(
        errorData.error?.message || `HTTP error! status: ${response.status}`
      );
    }

    const reader = response.body.getReader();
    const decoder = new TextDecoder();

    let fullResponse = "";
    let chunkCount = 0;

    while (true) {
      const { done, value } = await reader.read();
      if (done) break;

      const chunk = decoder.decode(value, { stream: true });
      const lines = chunk.split("\n");

      for (const line of lines) {
        if (line.startsWith("data: ")) {
          const data = line.slice(6).trim();

          if (data === "[DONE]") {
            console.log("‚úÖ R√©ponse compl√®te (brute):", fullResponse);
            console.log("üìä Nombre de chunks:", chunkCount);
            return;
          }

          try {
            const parsed = JSON.parse(data);
            const rawContent = parsed.choices?.[0]?.delta?.content || "";

            if (rawContent) {
              chunkCount++;
              fullResponse += rawContent;
              console.log(
                `üì¶ Chunk ${chunkCount}:`,
                JSON.stringify(rawContent)
              );
              onChunk(rawContent);
            }
          } catch (e) {
            // Skip unparseable lines
            if (data !== "") {
              console.warn("Could not parse SSE data:", data);
            }
          }
        }
      }
    }
  } catch (error) {
    console.error("‚ùå Chat error:", error);
    throw error;
  }
}
